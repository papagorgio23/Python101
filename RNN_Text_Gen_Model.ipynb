{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Text Gen Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM56pVorAKk4kG4zGoA5bpW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papagorgio23/Python101/blob/master/RNN_Text_Gen_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iu6YkcTx0dr",
        "colab_type": "text"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyQ9ByOwx3-f",
        "colab_type": "text"
      },
      "source": [
        "## Load Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMmBF1hJy1mN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "72a91e83-ca38-401f-e2dc-b178de09f417"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_mVEJoNy1i0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf61c7dc-ef51-4418-c822-0be336b54582"
      },
      "source": [
        "# set working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Python 101/\")\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Python 101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nAQlNYCxoTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Q2CMxjx2VR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "50c705c1-392b-4c05-c394-b9df27e4edba"
      },
      "source": [
        "# load document\n",
        "in_filename = 'plato.txt'\n",
        "\n",
        "doc = load_doc(in_filename)\n",
        "print(doc[:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "BOOK I.\n",
            "\n",
            "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
            "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
            "Artemis.); and also because I wanted to see in wh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbxN6Y4q0eru",
        "colab_type": "text"
      },
      "source": [
        "## Clean Text\n",
        "\n",
        "We need to transform the raw text into a sequence of tokens or words that we can use as a source to train the model.\n",
        "\n",
        "Based on reviewing the raw text (above), below are some specific operations we will perform to clean the text. You may want to explore more cleaning operations yourself as an extension.\n",
        "\n",
        "Replace ‘–‘ with a white space so we can split words better.\n",
        "Split words based on white space.\n",
        "Remove all punctuation from words to reduce the vocabulary size (e.g. ‘What?’ becomes ‘What’).\n",
        "Remove all words that are not alphabetic to remove standalone punctuation tokens.\n",
        "Normalize all words to lowercase to reduce the vocabulary size.\n",
        "Vocabulary size is a big deal with language modeling. A smaller vocabulary results in a smaller model that trains faster.\n",
        "\n",
        "We can implement each of these cleaning operations in this order in a function. Below is the function clean_doc() that takes a loaded document as an argument and returns an array of clean tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYZTF0cuyIuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        " \n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV_Re19R0ZeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "27cef576-e8ae-4d60-a55e-45b4c8032fab"
      },
      "source": [
        "\n",
        "# clean document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:200])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['book', 'i', 'i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the', 'procession', 'of', 'the', 'inhabitants', 'but', 'that', 'of', 'the', 'thracians', 'was', 'equally', 'if', 'not', 'more', 'beautiful', 'when', 'we', 'had', 'finished', 'our', 'prayers', 'and', 'viewed', 'the', 'spectacle', 'we', 'turned', 'in', 'the', 'direction', 'of', 'the', 'city', 'and', 'at', 'that', 'instant', 'polemarchus', 'the', 'son', 'of', 'cephalus', 'chanced', 'to', 'catch', 'sight', 'of', 'us', 'from', 'a', 'distance', 'as', 'we', 'were', 'starting', 'on', 'our', 'way', 'home', 'and', 'told', 'his', 'servant', 'to', 'run', 'and', 'bid', 'us', 'wait', 'for', 'him', 'the', 'servant', 'took', 'hold', 'of', 'me', 'by', 'the', 'cloak', 'behind', 'and', 'said', 'polemarchus', 'desires', 'you', 'to', 'wait', 'i', 'turned', 'round', 'and', 'asked', 'him', 'where', 'his', 'master', 'was', 'there', 'he', 'is', 'said', 'the', 'youth', 'coming', 'after', 'you', 'if', 'you', 'will', 'only', 'wait', 'certainly', 'we', 'will', 'said', 'glaucon', 'and', 'in', 'a', 'few', 'minutes', 'polemarchus', 'appeared', 'and', 'with', 'him', 'adeimantus', 'glaucons', 'brother', 'niceratus', 'the', 'son', 'of', 'nicias', 'and', 'several', 'others', 'who', 'had', 'been', 'at', 'the', 'procession', 'polemarchus', 'said']\n",
            "Total Tokens: 121527\n",
            "Unique Tokens: 7671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRjPYsGo4LRS",
        "colab_type": "text"
      },
      "source": [
        "## Organize in Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMljBscI0b5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14b29a80-76f6-42ee-e1ce-124b5d36064c"
      },
      "source": [
        "# organize into sequences of tokens\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 121476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDIWWr41I3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0PlJIC61Pja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save sequences to file\n",
        "out_filename = 'republic_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qto6Zi2T4D7a",
        "colab_type": "text"
      },
      "source": [
        "## Load Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7oB8SyB1TK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'republic_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7gHycEq5FCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load packages\n",
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVDTmqjV4Gbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YfXgWV54UiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9he5XHxI4t40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72912f56-c007-4ba2-b9c9-1a349ee3584c"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtu4yd5O4wN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate into input and output\n",
        "sequences = array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1unZjmY_41Yg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "95517c42-c48f-498a-ade0-3d6502381b74"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 50)            383600    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7672)              774872    \n",
            "=================================================================\n",
            "Total params: 1,309,372\n",
            "Trainable params: 1,309,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agq81kqo552J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "6a10b95a-d63a-4d8e-f0c0-16e1f1085f91"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=256, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "121476/121476 [==============================] - 266s 2ms/step - loss: 6.1157 - acc: 0.0706\n",
            "Epoch 2/20\n",
            "121476/121476 [==============================] - 265s 2ms/step - loss: 5.8368 - acc: 0.0966\n",
            "Epoch 3/20\n",
            "121476/121476 [==============================] - 269s 2ms/step - loss: 5.6872 - acc: 0.1069\n",
            "Epoch 4/20\n",
            "121476/121476 [==============================] - 269s 2ms/step - loss: 5.5493 - acc: 0.1236\n",
            "Epoch 5/20\n",
            "121476/121476 [==============================] - 267s 2ms/step - loss: 5.4432 - acc: 0.1355\n",
            "Epoch 6/20\n",
            "121476/121476 [==============================] - 264s 2ms/step - loss: 5.3535 - acc: 0.1440\n",
            "Epoch 7/20\n",
            "121476/121476 [==============================] - 264s 2ms/step - loss: 5.2761 - acc: 0.1503\n",
            "Epoch 8/20\n",
            "121476/121476 [==============================] - 267s 2ms/step - loss: 5.2114 - acc: 0.1549\n",
            "Epoch 9/20\n",
            "121476/121476 [==============================] - 270s 2ms/step - loss: 5.1516 - acc: 0.1583\n",
            "Epoch 10/20\n",
            "121476/121476 [==============================] - 275s 2ms/step - loss: 5.0961 - acc: 0.1621\n",
            "Epoch 11/20\n",
            "121476/121476 [==============================] - 273s 2ms/step - loss: 5.0463 - acc: 0.1643\n",
            "Epoch 12/20\n",
            "121476/121476 [==============================] - 269s 2ms/step - loss: 4.9976 - acc: 0.1679\n",
            "Epoch 13/20\n",
            "121476/121476 [==============================] - 267s 2ms/step - loss: 4.9482 - acc: 0.1702\n",
            "Epoch 14/20\n",
            "121476/121476 [==============================] - 271s 2ms/step - loss: 4.9024 - acc: 0.1732\n",
            "Epoch 15/20\n",
            "121476/121476 [==============================] - 269s 2ms/step - loss: 4.8574 - acc: 0.1770\n",
            "Epoch 16/20\n",
            "121476/121476 [==============================] - 273s 2ms/step - loss: 4.8156 - acc: 0.1795\n",
            "Epoch 17/20\n",
            "121476/121476 [==============================] - 272s 2ms/step - loss: 4.7808 - acc: 0.1821\n",
            "Epoch 18/20\n",
            "121476/121476 [==============================] - 277s 2ms/step - loss: 4.7402 - acc: 0.1860\n",
            "Epoch 19/20\n",
            "121476/121476 [==============================] - 270s 2ms/step - loss: 4.7026 - acc: 0.1885\n",
            "Epoch 20/20\n",
            "121476/121476 [==============================] - 270s 2ms/step - loss: 4.6666 - acc: 0.1906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc1f89fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPxwmwh8d9od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN7-CijfED0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-pA1fBznIY",
        "colab_type": "text"
      },
      "source": [
        "## Use the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gdycLEIeRJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)\n",
        "\n",
        "# load cleaned text sequences\n",
        "in_filename = 'republic_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk0-LZqwzvNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "458b697f-2fc9-4815-de33-149b70f2de1c"
      },
      "source": [
        "# select a seed text\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text + '\\n')\n",
        "\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "may presuppose yes he said so much as that you may and as for the words there will surely be no difference between words which are and which are not set to music both will conform to the same laws and these have been already determined by us yes and the\n",
            "\n",
            "same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and the same and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWMnKxHOzx6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3ebd2dab-cc71-45fb-b276-99ec67f17da3"
      },
      "source": [
        "lines[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cknIvbMjz4LR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77f816d6-b06a-4a6d-a00c-e3f3f2224d80"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'may presuppose yes he said so much as that you may and as for the words there will surely be no difference between words which are and which are not set to music both will conform to the same laws and these have been already determined by us yes and the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaWR__Nxz92C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}