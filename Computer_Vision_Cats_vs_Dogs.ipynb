{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer Vision - Cats vs Dogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papagorgio23/Python101/blob/master/Computer_Vision_Cats_vs_Dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2XAd8aOTgm5",
        "colab_type": "text"
      },
      "source": [
        "Northwestern MSDS\n",
        "\n",
        "422 - Practical Machine Learning\n",
        "\n",
        "Jason Lee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61IKs6PEPKBD",
        "colab_type": "text"
      },
      "source": [
        "## Cats vs. Dogs + Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1nWGK9ATocL",
        "colab_type": "text"
      },
      "source": [
        "## Management Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7RNXobj4crH",
        "colab_type": "text"
      },
      "source": [
        "Assume that we are providing advice to a website provider who is looking for tools to automatically label images provided by end users. As we look across the factors in the study, making recommendations to management about image classification, we are most concerned about achieving the highest possible accuracy in image classification. That is, we should be willing to sacrifice training time for model accuracy. Part of this recommendation may concern information about the initial images themselves (input data for the classification task). \n",
        "\n",
        "*   What type of machine learning model works best? \n",
        "\n",
        "*   If it is a convolutional neural network, what type of network should we use?\n",
        "\n",
        "*   What types of images work best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjNR_pzuTxSs",
        "colab_type": "text"
      },
      "source": [
        "# Programming Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch5fNiveTzrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import base packages into the namespace for this program\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from datetime import datetime\n",
        "\n",
        "# modeling routines from Scikit Learn packages\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5sFeW13T3YY",
        "colab_type": "text"
      },
      "source": [
        "## Ingest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPNoDfpXO-zQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "4ddcba69-e6ac-48fc-d1bc-aaa21be0bebb"
      },
      "source": [
        "# get data\n",
        "import os\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "\n",
        "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
        "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
        "\n",
        "def maybe_download(filename):\n",
        "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
        "    if not os.path.exists(WORK_DIRECTORY):\n",
        "        os.mkdir(WORK_DIRECTORY)\n",
        "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
        "    if not os.path.exists(filepath):\n",
        "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
        "        statinfo = os.stat(filepath)\n",
        "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "    else:\n",
        "        print('Already downloaded', filename)\n",
        "    return filepath\n",
        "\n",
        "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
        "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
        "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
        "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQyNZMmkSEIj",
        "colab_type": "text"
      },
      "source": [
        "## View data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYASLHEJP313",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "82eca5d2-bd3d-4e67-9f76-e36e19300aaa"
      },
      "source": [
        "\n",
        "import gzip, binascii, struct, numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with gzip.open(test_data_filename) as f:\n",
        "    # Print the header fields.\n",
        "    for field in ['magic number', 'image count', 'rows', 'columns']:\n",
        "        # struct.unpack reads the binary data provided by f.read.\n",
        "        # The format string '>i' decodes a big-endian integer, which\n",
        "        # is the encoding of the data.\n",
        "        print(field, struct.unpack('>i', f.read(4))[0])\n",
        "    \n",
        "    # Read the first 28x28 set of pixel values. \n",
        "    # Each pixel is one byte, [0, 255], a uint8.\n",
        "    buf = f.read(28 * 28)\n",
        "    image = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
        "  \n",
        "    # Print the first few values of image.\n",
        "    print('First 10 pixels:', image[:10])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "magic number 2051\n",
            "image count 10000\n",
            "rows 28\n",
            "columns 28\n",
            "First 10 pixels: [0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5e_DZtaSJ33",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrUK_05iQS7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "82d97b06-91c9-4a33-fbed-13fe20906632"
      },
      "source": [
        "get_ipython().magic(u'matplotlib inline')\n",
        "\n",
        "# We'll show the image and its pixel value histogram side-by-side.\n",
        "_, (ax1, ax2) = plt.subplots(1, 2)\n",
        "\n",
        "# To interpret the values as a 28x28 image, we need to reshape\n",
        "# the numpy array, which is one dimensional.\n",
        "ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys);\n",
        "\n",
        "ax2.hist(image, bins=20, range=[0,255]);\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD7CAYAAAClvBX1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QinpFaijSRjG",
        "colab_type": "text"
      },
      "source": [
        "## Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djZC0wjaQqW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "b5c014fc-a541-482a-8be9-e35880e4e171"
      },
      "source": [
        "\n",
        "# Let's convert the uint8 image to 32 bit floats and rescale \n",
        "# the values to be centered around 0, between [-0.5, 0.5]. \n",
        "# \n",
        "# We again plot the image and histogram to check that we \n",
        "# haven't mangled the data.\n",
        "scaled = image.astype(numpy.float32)\n",
        "scaled = (scaled - (255 / 2.0)) / 255\n",
        "_, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(scaled.reshape(28, 28), cmap=plt.cm.Greys);\n",
        "ax2.hist(scaled, bins=20, range=[-0.5, 0.5]);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD7CAYAAAB37B+tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfHdFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkU5uezBQ8HB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "2d17553b-fb14-4da7-c221-11a6c76cdb87"
      },
      "source": [
        "\n",
        "with gzip.open(test_labels_filename) as f:\n",
        "    # Print the header fields.\n",
        "    for field in ['magic number', 'label count']:\n",
        "        print(field, struct.unpack('>i', f.read(4))[0])\n",
        "\n",
        "    print('First label:', struct.unpack('B', f.read(1))[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "magic number 2049\n",
            "label count 10000\n",
            "First label: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ34cblmRKPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "57ea31f8-2e23-4684-c02c-ccc1621cb4f2"
      },
      "source": [
        "\n",
        "IMAGE_SIZE = 28\n",
        "PIXEL_DEPTH = 255\n",
        "\n",
        "def extract_data(filename, num_images):\n",
        "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
        "  \n",
        "    For MNIST data, the number of channels is always 1.\n",
        "\n",
        "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
        "    \"\"\"\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        # Skip the magic number and dimensions; we know these values.\n",
        "        bytestream.read(16)\n",
        "\n",
        "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
        "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
        "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
        "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "        return data\n",
        "\n",
        "train_data = extract_data(train_data_filename, 60000)\n",
        "test_data = extract_data(test_data_filename, 10000)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzHQFD5pRXJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "a9b317d4-a482-49c8-f59b-21f00cafccab"
      },
      "source": [
        "\n",
        "print('Training data shape', train_data.shape)\n",
        "_, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(train_data[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
        "ax2.imshow(train_data[1].reshape(28, 28), cmap=plt.cm.Greys);\n",
        "\n",
        "\n",
        "# Looks good. Now we know how to index our full set of training and test images.\n",
        "\n",
        "# ### Label data\n",
        "# \n",
        "# Let's move on to loading the full set of labels. As is typical in classification problems, we'll convert our input labels into a [1-hot](https://en.wikipedia.org/wiki/One-hot) encoding over a length 10 vector corresponding to 10 digits. The vector [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], for example, would correspond to the digit 1.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape (60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAC4CAYAAAAscG03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRyAskEDrUJH",
        "colab_type": "text"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_pu5QUbRrSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "44a45ed7-3cfa-4f45-85d9-37979a28f9d8"
      },
      "source": [
        "\n",
        "\n",
        "NUM_LABELS = 10\n",
        "\n",
        "def extract_labels(filename, num_images):\n",
        "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
        "    print('Extracting', filename)\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        # Skip the magic number and count; we know these values.\n",
        "        bytestream.read(8)\n",
        "        buf = bytestream.read(1 * num_images)\n",
        "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
        "    # Convert to dense 1-hot representation.\n",
        "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
        "\n",
        "train_labels = extract_labels(train_labels_filename, 60000)\n",
        "test_labels = extract_labels(test_labels_filename, 10000)\n",
        "\n",
        "\n",
        "# As with our image data, we'll double-check that our 1-hot encoding of the first few values matches our expectations.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J1qf1ULR28Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "73a7ec3b-30f0-4f24-f5dc-a8e74d106aa8"
      },
      "source": [
        "\n",
        "\n",
        "print('Training labels shape', train_labels.shape)\n",
        "print('First label vector', train_labels[0])\n",
        "print('Second label vector', train_labels[1])\n",
        "\n",
        "\n",
        "# The 1-hot encoding looks reasonable.\n",
        "# \n",
        "# ### Segmenting data into training, test, and validation\n",
        "# \n",
        "# The final step in preparing our data is to split it into three sets: training, test, and validation. This isn't the format of the original data set, so we'll take a small slice of the training data and treat that as our validation set.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training labels shape (60000, 10)\n",
            "First label vector [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Second label vector [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN2_m6JsR79B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6aea6abf-648c-401f-bfa8-c4ec9716831c"
      },
      "source": [
        "\n",
        "\n",
        "VALIDATION_SIZE = 5000\n",
        "\n",
        "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
        "validation_labels = train_labels[:VALIDATION_SIZE]\n",
        "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
        "train_labels = train_labels[VALIDATION_SIZE:]\n",
        "\n",
        "train_size = train_labels.shape[0]\n",
        "\n",
        "print('Validation shape', validation_data.shape)\n",
        "print('Train size', train_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation shape (5000, 28, 28, 1)\n",
            "Train size 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHXH7lR2Rr_G",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jEoNH1tG6s",
        "colab_type": "text"
      },
      "source": [
        "I will test out 3 different types of Neural Networks\n",
        "\n",
        "\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnbbJO5mtdh0",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdWVfUrXrY-w",
        "colab_type": "text"
      },
      "source": [
        "### Build Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRUJjQyWSKAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# We'll bundle groups of examples during training for efficiency.\n",
        "# This defines the size of the batch.\n",
        "BATCH_SIZE = 60\n",
        "# We have only one channel in our grayscale images.\n",
        "NUM_CHANNELS = 1\n",
        "# The random seed that defines initialization.\n",
        "SEED = 42\n",
        "\n",
        "# This is where training samples and labels are fed to the graph.\n",
        "# These placeholder nodes will be fed a batch of training data at each\n",
        "# training step, which we'll write once we define the graph structure.\n",
        "train_data_node = tf.placeholder(\n",
        "  tf.float32, shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
        "\n",
        "train_labels_node = tf.placeholder(\n",
        "    tf.float32, shape=(BATCH_SIZE, NUM_LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXEUcMdlSj3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the validation and test data, we'll just hold the entire dataset in\n",
        "# one constant node.\n",
        "validation_data_node = tf.constant(validation_data)\n",
        "test_data_node = tf.constant(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM4BkzvBSm4f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b0dc40d7-c11a-4901-cf47-21d5d5db1759"
      },
      "source": [
        "\n",
        "# The variables below hold all the trainable weights. For each, the\n",
        "# parameter defines how the variables will be initialized.\n",
        "conv1_weights = tf.Variable(\n",
        "  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "conv1_biases = tf.Variable(tf.zeros([32]))\n",
        "conv2_weights = tf.Variable(\n",
        "  tf.truncated_normal([5, 5, 32, 64],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
        "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
        "fc2_weights = tf.Variable(\n",
        "  tf.truncated_normal([512, NUM_LABELS],\n",
        "                      stddev=0.1,\n",
        "                      seed=SEED))\n",
        "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
        "\n",
        "print('Done')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLH0vA4_rrww",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Relu Activation\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKEMezo5Sy4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f5079e39-eda8-45e8-856e-469389553af1"
      },
      "source": [
        "\n",
        "def model(data, train=False):\n",
        "    \"\"\"The Model definition.\"\"\"\n",
        "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
        "    # the same size as the input). Note that {strides} is a 4D array whose\n",
        "    # shape matches the data layout: [image index, y, x, depth].\n",
        "    conv = tf.nn.conv2d(data,\n",
        "                        conv1_weights,\n",
        "                        strides=[1, 1, 1, 1],\n",
        "                        padding='SAME')\n",
        "\n",
        "    # Bias and rectified linear non-linearity.\n",
        "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
        "\n",
        "    # Max pooling. The kernel size spec ksize also follows the layout of\n",
        "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
        "    pool = tf.nn.max_pool(relu,\n",
        "                          ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1],\n",
        "                          padding='SAME')\n",
        "    conv = tf.nn.conv2d(pool,\n",
        "                        conv2_weights,\n",
        "                        strides=[1, 1, 1, 1],\n",
        "                        padding='SAME')\n",
        "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
        "    pool = tf.nn.max_pool(relu,\n",
        "                          ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
        "    # fully connected layers.\n",
        "    pool_shape = pool.get_shape().as_list()\n",
        "    reshape = tf.reshape(\n",
        "        pool,\n",
        "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
        "  \n",
        "    # Fully connected layer. Note that the '+' operation automatically\n",
        "    # broadcasts the biases.\n",
        "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
        "\n",
        "    # Add a 50% dropout during training only. Dropout also scales\n",
        "    # activations such that no rescaling is needed at evaluation time.\n",
        "    if train:\n",
        "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
        "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0G4eaBvS0X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Having defined the basic structure of the graph, we're ready to stamp out multiple copies for training, testing, and validation.\n",
        "# \n",
        "# Here, we'll do some customizations depending on which graph we're constructing. `train_prediction` holds the training graph, for which we use cross-entropy loss and weight regularization. We'll adjust the learning rate during training -- that's handled by the `exponential_decay` operation, which is itself an argument to the `MomentumOptimizer` that performs the actual training.\n",
        "# \n",
        "# The vaildation and prediction graphs are much simpler the generate -- we need only create copies of the model with the validation and test inputs and a softmax classifier as the output.\n",
        "\n",
        "\n",
        "\n",
        "# Training computation: logits + cross-entropy loss.\n",
        "logits = model(train_data_node, True)\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "  labels=train_labels_node, logits=logits))\n",
        "\n",
        "# L2 regularization for the fully connected parameters.\n",
        "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
        "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
        "# Add the regularization term to the loss.\n",
        "loss += 5e-4 * regularizers\n",
        "\n",
        "# Optimizer: set up a variable that's incremented once per batch and\n",
        "# controls the learning rate decay.\n",
        "batch = tf.Variable(0)\n",
        "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
        "learning_rate = tf.train.exponential_decay(\n",
        "  0.01,                # Base learning rate.\n",
        "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
        "  train_size,          # Decay step.\n",
        "  0.95,                # Decay rate.\n",
        "  staircase=True)\n",
        "# Use simple momentum for the optimization.\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
        "                                       0.9).minimize(loss,\n",
        "                                                     global_step=batch)\n",
        "\n",
        "# Predictions for the minibatch, validation set and test set.\n",
        "train_prediction = tf.nn.softmax(logits)\n",
        "# We'll compute them only once in a while by calling their {eval()} method.\n",
        "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
        "test_prediction = tf.nn.softmax(model(test_data_node))\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7soATPiTM4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create a new interactive session that we'll use in\n",
        "# subsequent code cells.\n",
        "s = tf.InteractiveSession()\n",
        "\n",
        "# Use our newly created session as the default for \n",
        "# subsequent operations.\n",
        "s.as_default()\n",
        "\n",
        "# Initialize all the variables we defined above.\n",
        "tf.global_variables_initializer().run()\n",
        "\n",
        "\n",
        "# Now we're ready to perform operations on the graph. Let's start with one round of training. We're going to organize our training steps into batches for efficiency; i.e., training using a small set of examples at each step rather than a single example.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hV_pu5cTZ57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3e393ffb-7c96-4d8a-e270-3fae204083f1"
      },
      "source": [
        "\n",
        "\n",
        "BATCH_SIZE = 60\n",
        "\n",
        "# Grab the first BATCH_SIZE examples and labels.\n",
        "batch_data = train_data[:BATCH_SIZE, :, :, :]\n",
        "batch_labels = train_labels[:BATCH_SIZE]\n",
        "\n",
        "# This dictionary maps the batch data (as a numpy array) to the\n",
        "# node in the graph it should be fed to.\n",
        "feed_dict = {train_data_node: batch_data,\n",
        "             train_labels_node: batch_labels}\n",
        "\n",
        "# Run the graph and fetch some of the nodes.\n",
        "_, l, lr, predictions = s.run(\n",
        "  [optimizer, loss, learning_rate, train_prediction],\n",
        "  feed_dict=feed_dict)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNsTWmCRTdvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b8637636-2d3d-47c0-954a-9b6e785d0c7d"
      },
      "source": [
        "\n",
        "print(predictions[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.4470652e-05 3.5312430e-06 4.6149725e-03 3.5228557e-05 3.7312397e-01\n",
            " 4.1718615e-04 5.9920108e-06 1.7964175e-04 1.4388385e-04 6.2141114e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOXSl23jTd25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "cec1ef71-3265-49e3-d71f-203ec330a903"
      },
      "source": [
        "\n",
        "# The highest probability in the first entry.\n",
        "print('First prediction', numpy.argmax(predictions[0]))\n",
        "\n",
        "# But, predictions is actually a list of BATCH_SIZE probability vectors.\n",
        "print(predictions.shape)\n",
        "\n",
        "# So, we'll take the highest probability for each vector.\n",
        "print('All predictions', numpy.argmax(predictions, 1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First prediction 9\n",
            "(60, 10)\n",
            "All predictions [9 4 2 7 7 7 8 7 7 9 7 7 7 4 4 9 7 7 3 2 4 0 7 9 7 4 7 4 7 4 1 7 7 0 4 7 9\n",
            " 4 7 9 0 7 7 7 2 7 0 7 2 9 9 9 9 0 0 0 9 4 3 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWIdOcEpTtoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f34df688-0d59-4043-b974-421101dfb9e7"
      },
      "source": [
        "\n",
        "print('Batch labels', numpy.argmax(batch_labels, 1))\n",
        "\n",
        "\n",
        "# Now we can compare the predicted and label classes to compute the error rate and confusion matrix for this batch.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch labels [3 8 7 9 9 0 1 1 5 2 0 3 8 4 7 5 2 6 4 7 1 8 0 9 2 0 0 1 9 2 5 3 6 4 3 5 6\n",
            " 6 9 7 1 8 3 9 6 0 7 9 1 5 7 5 3 6 8 9 5 8 1 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD1xzKuMTd5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "62b86bd7-0419-4446-a626-ff7ce0bdb4d1"
      },
      "source": [
        "\n",
        "correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(batch_labels, 1))\n",
        "total = predictions.shape[0]\n",
        "\n",
        "print(float(correct) / float(total))\n",
        "\n",
        "confusions = numpy.zeros([10, 10], numpy.float32)\n",
        "bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(batch_labels, 1))\n",
        "for predicted, actual in bundled:\n",
        "  confusions[predicted, actual] += 1\n",
        "\n",
        "plt.grid(False)\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.yticks(numpy.arange(NUM_LABELS))\n",
        "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
        "\n",
        "\n",
        "# Now let's wrap this up into our scoring function."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD4CAYAAADb7cuFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf0i1WV1Q3xp4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc9yg7SxT523",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f97f91ba-93af-4d70-df4d-16fcaf13b44c"
      },
      "source": [
        "\n",
        "def error_rate(predictions, labels):\n",
        "    \"\"\"Return the error rate and confusions.\"\"\"\n",
        "    correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))\n",
        "    total = predictions.shape[0]\n",
        "\n",
        "    error = 100.0 - (100 * float(correct) / float(total))\n",
        "\n",
        "    confusions = numpy.zeros([10, 10], numpy.float32)\n",
        "    bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))\n",
        "    for predicted, actual in bundled:\n",
        "        confusions[predicted, actual] += 1\n",
        "    \n",
        "    return error, confusions\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb6TrKNxsROI",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBIfYLdVT8kN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "6082212a-3a2b-4ce7-ebf1-cf5327a812fb"
      },
      "source": [
        "# start timer\n",
        "start = datetime.now()\n",
        "\n",
        "\n",
        "# We'll need to train for some time to actually see useful predicted values. Let's define a loop that will go through our data. We'll print the loss and error periodically.\n",
        "# \n",
        "# Here, we want to iterate over the entire data set rather than just the first batch, so we'll need to slice the data to that end.\n",
        "# \n",
        "# (One pass through our training set will take some time on a CPU, so be patient if you are executing this notebook.)\n",
        "\n",
        "# Train over the first 1/4th of our training set.\n",
        "steps = train_size // BATCH_SIZE\n",
        "for step in range(steps):\n",
        "    # Compute the offset of the current minibatch in the data.\n",
        "    # Note that we could use better randomization across epochs.\n",
        "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
        "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
        "    # This dictionary maps the batch data (as a numpy array) to the\n",
        "    # node in the graph it should be fed to.\n",
        "    feed_dict = {train_data_node: batch_data,\n",
        "                 train_labels_node: batch_labels}\n",
        "    # Run the graph and fetch some of the nodes.\n",
        "    _, l, lr, predictions = s.run(\n",
        "      [optimizer, loss, learning_rate, train_prediction],\n",
        "      feed_dict=feed_dict)\n",
        "    \n",
        "    # Print out the loss periodically.\n",
        "    if step % 100 == 0:\n",
        "        error, _ = error_rate(predictions, batch_labels)\n",
        "        print('Step %d of %d' % (step, steps))\n",
        "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
        "        print('Validation error: %.1f%%' % error_rate(\n",
        "              validation_prediction.eval(), validation_labels)[0])\n",
        "\n",
        "\n",
        "# The error seems to have gone down. Let's evaluate the results using the test set.\n",
        "# \n",
        "# To help identify rare mispredictions, we'll include the raw count of each (prediction, label) pair in the confusion matrix.\n",
        "\n",
        "\n",
        "# end time for everything\n",
        "end = datetime.now()\n",
        "\n",
        "# print timing\n",
        "print(\"\\nTraining Time = {}\".format(end - start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 of 833\n",
            "Mini-batch loss: 3.02015 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 2.5%\n",
            "Step 100 of 833\n",
            "Mini-batch loss: 2.95736 Error: 5.00000 Learning rate: 0.00950\n",
            "Validation error: 2.4%\n",
            "Step 200 of 833\n",
            "Mini-batch loss: 2.83340 Error: 0.00000 Learning rate: 0.00950\n",
            "Validation error: 2.1%\n",
            "Step 300 of 833\n",
            "Mini-batch loss: 2.83317 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 2.5%\n",
            "Step 400 of 833\n",
            "Mini-batch loss: 2.85592 Error: 3.33333 Learning rate: 0.00950\n",
            "Validation error: 2.2%\n",
            "Step 500 of 833\n",
            "Mini-batch loss: 2.78945 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 2.0%\n",
            "Step 600 of 833\n",
            "Mini-batch loss: 2.75050 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 2.0%\n",
            "Step 700 of 833\n",
            "Mini-batch loss: 2.71311 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 2.0%\n",
            "Step 800 of 833\n",
            "Mini-batch loss: 2.73619 Error: 1.66667 Learning rate: 0.00950\n",
            "Validation error: 2.1%\n",
            "\n",
            "Training Time = 0:02:56.716146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUywYB9ptVPn",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CqdpSOnwKCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "175fd37a-6c11-4cc0-8ef4-9ab3abbd8163"
      },
      "source": [
        "print(test_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9200000000000017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo3IY1KcvCqG",
        "colab_type": "text"
      },
      "source": [
        "## Basic Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOEB5uc-ziEE",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj_WTwBWzcKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "42a5b501-5368-43f8-8a14-174868c0d5d4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekla4KTmvEH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up model\n",
        "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
        "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=10,\n",
        "                                             feature_columns=feature_columns)\n",
        "\n",
        "\n",
        "y_train = y_train.astype('int64')\n",
        "y_test = y_test.astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRAG3hVvzmWY",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s6OidQcvgqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13801
        },
        "outputId": "9028398f-f1fa-421b-99c0-e67f36ef5709"
      },
      "source": [
        "# start timer\n",
        "start = datetime.now()\n",
        "\n",
        "# train model\n",
        "dnn_clf.fit(x = x_train, y = y_train, batch_size = 50, steps = 40000)\n",
        "\n",
        "# end time for everything\n",
        "end = datetime.now()\n",
        "\n",
        "# print timing\n",
        "print(\"\\nTraining Time = {}\".format(end - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-13881b1d7113>:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From <ipython-input-8-13881b1d7113>:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From <ipython-input-8-13881b1d7113>:4: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:508: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/feature_column.py:1874: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:677: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp1ao_uxgb/model.ckpt.\n",
            "INFO:tensorflow:loss = 171.84549, step = 1\n",
            "INFO:tensorflow:global_step/sec: 237.963\n",
            "INFO:tensorflow:loss = 1.3184097, step = 101 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.401\n",
            "INFO:tensorflow:loss = 0.9594852, step = 201 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.841\n",
            "INFO:tensorflow:loss = 1.4998163, step = 301 (0.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.101\n",
            "INFO:tensorflow:loss = 0.89618105, step = 401 (0.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.056\n",
            "INFO:tensorflow:loss = 0.94875234, step = 501 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.553\n",
            "INFO:tensorflow:loss = 0.6564656, step = 601 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.367\n",
            "INFO:tensorflow:loss = 0.4999185, step = 701 (0.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.409\n",
            "INFO:tensorflow:loss = 0.75034964, step = 801 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.899\n",
            "INFO:tensorflow:loss = 0.6816992, step = 901 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.404\n",
            "INFO:tensorflow:loss = 0.44637343, step = 1001 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.077\n",
            "INFO:tensorflow:loss = 1.1156814, step = 1101 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.5\n",
            "INFO:tensorflow:loss = 0.4562084, step = 1201 (0.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.085\n",
            "INFO:tensorflow:loss = 0.5437898, step = 1301 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.998\n",
            "INFO:tensorflow:loss = 0.6131974, step = 1401 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.605\n",
            "INFO:tensorflow:loss = 0.5812582, step = 1501 (0.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.658\n",
            "INFO:tensorflow:loss = 0.52630985, step = 1601 (0.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.088\n",
            "INFO:tensorflow:loss = 0.8315419, step = 1701 (0.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.546\n",
            "INFO:tensorflow:loss = 0.6447301, step = 1801 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 223.94\n",
            "INFO:tensorflow:loss = 0.24586384, step = 1901 (0.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.497\n",
            "INFO:tensorflow:loss = 0.33816433, step = 2001 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.345\n",
            "INFO:tensorflow:loss = 0.4087189, step = 2101 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.384\n",
            "INFO:tensorflow:loss = 0.27818397, step = 2201 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.749\n",
            "INFO:tensorflow:loss = 0.51749486, step = 2301 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.539\n",
            "INFO:tensorflow:loss = 0.13406578, step = 2401 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.45\n",
            "INFO:tensorflow:loss = 0.35307738, step = 2501 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.622\n",
            "INFO:tensorflow:loss = 0.34055173, step = 2601 (0.437 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.385\n",
            "INFO:tensorflow:loss = 0.35140893, step = 2701 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.699\n",
            "INFO:tensorflow:loss = 0.2700674, step = 2801 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.93\n",
            "INFO:tensorflow:loss = 0.31195086, step = 2901 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.438\n",
            "INFO:tensorflow:loss = 0.10263587, step = 3001 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.379\n",
            "INFO:tensorflow:loss = 0.31152394, step = 3101 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.032\n",
            "INFO:tensorflow:loss = 0.31989646, step = 3201 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.818\n",
            "INFO:tensorflow:loss = 0.16931196, step = 3301 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.186\n",
            "INFO:tensorflow:loss = 0.21335842, step = 3401 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.82\n",
            "INFO:tensorflow:loss = 0.27656478, step = 3501 (0.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.595\n",
            "INFO:tensorflow:loss = 0.42808038, step = 3601 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.622\n",
            "INFO:tensorflow:loss = 0.505042, step = 3701 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 218.472\n",
            "INFO:tensorflow:loss = 0.46760654, step = 3801 (0.458 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.407\n",
            "INFO:tensorflow:loss = 0.48306844, step = 3901 (0.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.309\n",
            "INFO:tensorflow:loss = 0.3565347, step = 4001 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.243\n",
            "INFO:tensorflow:loss = 0.18972051, step = 4101 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.251\n",
            "INFO:tensorflow:loss = 0.119254224, step = 4201 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.149\n",
            "INFO:tensorflow:loss = 0.38390797, step = 4301 (0.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.412\n",
            "INFO:tensorflow:loss = 0.27350605, step = 4401 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.702\n",
            "INFO:tensorflow:loss = 0.23058088, step = 4501 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.395\n",
            "INFO:tensorflow:loss = 0.18149285, step = 4601 (0.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.376\n",
            "INFO:tensorflow:loss = 0.27212512, step = 4701 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.575\n",
            "INFO:tensorflow:loss = 0.052940134, step = 4801 (0.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.652\n",
            "INFO:tensorflow:loss = 0.7013004, step = 4901 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.892\n",
            "INFO:tensorflow:loss = 0.20647196, step = 5001 (0.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.557\n",
            "INFO:tensorflow:loss = 0.29740387, step = 5101 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.675\n",
            "INFO:tensorflow:loss = 0.24861881, step = 5201 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.036\n",
            "INFO:tensorflow:loss = 0.23037201, step = 5301 (0.419 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.873\n",
            "INFO:tensorflow:loss = 0.23526607, step = 5401 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.452\n",
            "INFO:tensorflow:loss = 0.28451565, step = 5501 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.587\n",
            "INFO:tensorflow:loss = 0.24950218, step = 5601 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.36\n",
            "INFO:tensorflow:loss = 0.11223983, step = 5701 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.626\n",
            "INFO:tensorflow:loss = 0.47713792, step = 5801 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.12\n",
            "INFO:tensorflow:loss = 0.30340734, step = 5901 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.212\n",
            "INFO:tensorflow:loss = 0.23195061, step = 6001 (0.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.33\n",
            "INFO:tensorflow:loss = 0.2081552, step = 6101 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.11\n",
            "INFO:tensorflow:loss = 0.143659, step = 6201 (0.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.214\n",
            "INFO:tensorflow:loss = 0.34827718, step = 6301 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.143\n",
            "INFO:tensorflow:loss = 0.12116007, step = 6401 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.375\n",
            "INFO:tensorflow:loss = 0.20596762, step = 6501 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.939\n",
            "INFO:tensorflow:loss = 0.1625383, step = 6601 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.755\n",
            "INFO:tensorflow:loss = 0.13020362, step = 6701 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.023\n",
            "INFO:tensorflow:loss = 0.46395573, step = 6801 (0.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.007\n",
            "INFO:tensorflow:loss = 0.60656756, step = 6901 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.041\n",
            "INFO:tensorflow:loss = 0.12850738, step = 7001 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.745\n",
            "INFO:tensorflow:loss = 0.18481359, step = 7101 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.606\n",
            "INFO:tensorflow:loss = 0.13708666, step = 7201 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.32\n",
            "INFO:tensorflow:loss = 0.28187367, step = 7301 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.381\n",
            "INFO:tensorflow:loss = 0.49361214, step = 7401 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 229.197\n",
            "INFO:tensorflow:loss = 0.27788156, step = 7501 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.975\n",
            "INFO:tensorflow:loss = 0.108403504, step = 7601 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.248\n",
            "INFO:tensorflow:loss = 0.13030139, step = 7701 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.819\n",
            "INFO:tensorflow:loss = 0.117973566, step = 7801 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.66\n",
            "INFO:tensorflow:loss = 0.24933578, step = 7901 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.724\n",
            "INFO:tensorflow:loss = 0.32774854, step = 8001 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.376\n",
            "INFO:tensorflow:loss = 0.066580445, step = 8101 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.541\n",
            "INFO:tensorflow:loss = 0.3983401, step = 8201 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.088\n",
            "INFO:tensorflow:loss = 0.065138824, step = 8301 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.626\n",
            "INFO:tensorflow:loss = 0.3295458, step = 8401 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.796\n",
            "INFO:tensorflow:loss = 0.18706222, step = 8501 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.399\n",
            "INFO:tensorflow:loss = 0.24866916, step = 8601 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.841\n",
            "INFO:tensorflow:loss = 0.28451476, step = 8701 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.06\n",
            "INFO:tensorflow:loss = 0.15382713, step = 8801 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.753\n",
            "INFO:tensorflow:loss = 0.085896656, step = 8901 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.948\n",
            "INFO:tensorflow:loss = 0.14091872, step = 9001 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.032\n",
            "INFO:tensorflow:loss = 0.58383864, step = 9101 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.797\n",
            "INFO:tensorflow:loss = 0.32988805, step = 9201 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.792\n",
            "INFO:tensorflow:loss = 0.10467501, step = 9301 (0.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.933\n",
            "INFO:tensorflow:loss = 0.21827482, step = 9401 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.402\n",
            "INFO:tensorflow:loss = 0.1129559, step = 9501 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.41\n",
            "INFO:tensorflow:loss = 0.11080184, step = 9601 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.697\n",
            "INFO:tensorflow:loss = 0.10128377, step = 9701 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.044\n",
            "INFO:tensorflow:loss = 0.20148514, step = 9801 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.705\n",
            "INFO:tensorflow:loss = 0.12952314, step = 9901 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.419\n",
            "INFO:tensorflow:loss = 0.124124825, step = 10001 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.596\n",
            "INFO:tensorflow:loss = 0.22185269, step = 10101 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.948\n",
            "INFO:tensorflow:loss = 0.3101839, step = 10201 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.394\n",
            "INFO:tensorflow:loss = 0.46528634, step = 10301 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.922\n",
            "INFO:tensorflow:loss = 0.29311183, step = 10401 (0.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.62\n",
            "INFO:tensorflow:loss = 0.36550328, step = 10501 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.066\n",
            "INFO:tensorflow:loss = 0.35651097, step = 10601 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.753\n",
            "INFO:tensorflow:loss = 0.20168695, step = 10701 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.085\n",
            "INFO:tensorflow:loss = 0.47957027, step = 10801 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.052\n",
            "INFO:tensorflow:loss = 0.33130056, step = 10901 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.332\n",
            "INFO:tensorflow:loss = 0.25389457, step = 11001 (0.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.875\n",
            "INFO:tensorflow:loss = 0.1731968, step = 11101 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.334\n",
            "INFO:tensorflow:loss = 0.08522905, step = 11201 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.272\n",
            "INFO:tensorflow:loss = 0.025318122, step = 11301 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.332\n",
            "INFO:tensorflow:loss = 0.1207086, step = 11401 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.877\n",
            "INFO:tensorflow:loss = 0.11592713, step = 11501 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.28\n",
            "INFO:tensorflow:loss = 0.18640003, step = 11601 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.89\n",
            "INFO:tensorflow:loss = 0.3720969, step = 11701 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.743\n",
            "INFO:tensorflow:loss = 0.15021662, step = 11801 (0.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.388\n",
            "INFO:tensorflow:loss = 0.14127398, step = 11901 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.724\n",
            "INFO:tensorflow:loss = 0.11586039, step = 12001 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.651\n",
            "INFO:tensorflow:loss = 0.12586275, step = 12101 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.534\n",
            "INFO:tensorflow:loss = 0.3613776, step = 12201 (0.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.606\n",
            "INFO:tensorflow:loss = 0.18227462, step = 12301 (0.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.549\n",
            "INFO:tensorflow:loss = 0.19036427, step = 12401 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.071\n",
            "INFO:tensorflow:loss = 0.13787274, step = 12501 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.748\n",
            "INFO:tensorflow:loss = 0.2415926, step = 12601 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.51\n",
            "INFO:tensorflow:loss = 0.35695088, step = 12701 (0.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.469\n",
            "INFO:tensorflow:loss = 0.04545614, step = 12801 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.589\n",
            "INFO:tensorflow:loss = 0.18389958, step = 12901 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.401\n",
            "INFO:tensorflow:loss = 0.23853014, step = 13001 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.545\n",
            "INFO:tensorflow:loss = 0.18662684, step = 13101 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.403\n",
            "INFO:tensorflow:loss = 0.18026984, step = 13201 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 235.392\n",
            "INFO:tensorflow:loss = 0.26602983, step = 13301 (0.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.285\n",
            "INFO:tensorflow:loss = 0.25165874, step = 13401 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.872\n",
            "INFO:tensorflow:loss = 0.1944871, step = 13501 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.105\n",
            "INFO:tensorflow:loss = 0.050848026, step = 13601 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.244\n",
            "INFO:tensorflow:loss = 0.38348496, step = 13701 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.477\n",
            "INFO:tensorflow:loss = 0.41176778, step = 13801 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.102\n",
            "INFO:tensorflow:loss = 0.19321217, step = 13901 (0.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.797\n",
            "INFO:tensorflow:loss = 0.3156289, step = 14001 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.825\n",
            "INFO:tensorflow:loss = 0.16208106, step = 14101 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.04\n",
            "INFO:tensorflow:loss = 0.3194376, step = 14201 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.107\n",
            "INFO:tensorflow:loss = 0.28730378, step = 14301 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.685\n",
            "INFO:tensorflow:loss = 0.08319806, step = 14401 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.722\n",
            "INFO:tensorflow:loss = 0.10176423, step = 14501 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.761\n",
            "INFO:tensorflow:loss = 0.005679654, step = 14601 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 236.386\n",
            "INFO:tensorflow:loss = 0.048973866, step = 14701 (0.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.265\n",
            "INFO:tensorflow:loss = 0.24182004, step = 14801 (0.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.469\n",
            "INFO:tensorflow:loss = 0.15437357, step = 14901 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.713\n",
            "INFO:tensorflow:loss = 0.14441036, step = 15001 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.106\n",
            "INFO:tensorflow:loss = 0.38544455, step = 15101 (0.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.335\n",
            "INFO:tensorflow:loss = 0.10603029, step = 15201 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.112\n",
            "INFO:tensorflow:loss = 0.041392416, step = 15301 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.591\n",
            "INFO:tensorflow:loss = 0.08774004, step = 15401 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 237.572\n",
            "INFO:tensorflow:loss = 0.19635798, step = 15501 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.283\n",
            "INFO:tensorflow:loss = 0.19973783, step = 15601 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 237.682\n",
            "INFO:tensorflow:loss = 0.3291768, step = 15701 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.483\n",
            "INFO:tensorflow:loss = 0.1952945, step = 15801 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.956\n",
            "INFO:tensorflow:loss = 0.34159684, step = 15901 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.878\n",
            "INFO:tensorflow:loss = 0.3461252, step = 16001 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.147\n",
            "INFO:tensorflow:loss = 0.25875515, step = 16101 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.552\n",
            "INFO:tensorflow:loss = 0.110099465, step = 16201 (0.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.739\n",
            "INFO:tensorflow:loss = 0.16500482, step = 16301 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.108\n",
            "INFO:tensorflow:loss = 0.0882836, step = 16401 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.121\n",
            "INFO:tensorflow:loss = 0.106622085, step = 16501 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.415\n",
            "INFO:tensorflow:loss = 0.39271533, step = 16601 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.198\n",
            "INFO:tensorflow:loss = 0.18515167, step = 16701 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.755\n",
            "INFO:tensorflow:loss = 0.08065298, step = 16801 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 244.944\n",
            "INFO:tensorflow:loss = 0.38749585, step = 16901 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.866\n",
            "INFO:tensorflow:loss = 0.18308982, step = 17001 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.737\n",
            "INFO:tensorflow:loss = 0.21592405, step = 17101 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.642\n",
            "INFO:tensorflow:loss = 0.23840337, step = 17201 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.182\n",
            "INFO:tensorflow:loss = 0.037728287, step = 17301 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.241\n",
            "INFO:tensorflow:loss = 0.15862772, step = 17401 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.936\n",
            "INFO:tensorflow:loss = 0.45121455, step = 17501 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.538\n",
            "INFO:tensorflow:loss = 0.5071153, step = 17601 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.692\n",
            "INFO:tensorflow:loss = 0.058622207, step = 17701 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.737\n",
            "INFO:tensorflow:loss = 0.06620667, step = 17801 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.023\n",
            "INFO:tensorflow:loss = 0.22712396, step = 17901 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.544\n",
            "INFO:tensorflow:loss = 0.23547105, step = 18001 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.456\n",
            "INFO:tensorflow:loss = 0.11902716, step = 18101 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.89\n",
            "INFO:tensorflow:loss = 0.09224333, step = 18201 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.16\n",
            "INFO:tensorflow:loss = 0.13260621, step = 18301 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.884\n",
            "INFO:tensorflow:loss = 0.056448955, step = 18401 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.679\n",
            "INFO:tensorflow:loss = 0.07553289, step = 18501 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.113\n",
            "INFO:tensorflow:loss = 0.16025032, step = 18601 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.804\n",
            "INFO:tensorflow:loss = 0.06604752, step = 18701 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.632\n",
            "INFO:tensorflow:loss = 0.4978157, step = 18801 (0.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.335\n",
            "INFO:tensorflow:loss = 0.35112816, step = 18901 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.947\n",
            "INFO:tensorflow:loss = 0.25887078, step = 19001 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.85\n",
            "INFO:tensorflow:loss = 0.16284396, step = 19101 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.736\n",
            "INFO:tensorflow:loss = 0.18075909, step = 19201 (0.407 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.152\n",
            "INFO:tensorflow:loss = 0.05491416, step = 19301 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.339\n",
            "INFO:tensorflow:loss = 0.24867079, step = 19401 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.56\n",
            "INFO:tensorflow:loss = 0.101778835, step = 19501 (0.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.498\n",
            "INFO:tensorflow:loss = 0.23827568, step = 19601 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.935\n",
            "INFO:tensorflow:loss = 0.19389838, step = 19701 (0.413 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.645\n",
            "INFO:tensorflow:loss = 0.06502342, step = 19801 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.199\n",
            "INFO:tensorflow:loss = 0.05935289, step = 19901 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 237.357\n",
            "INFO:tensorflow:loss = 0.41289386, step = 20001 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.008\n",
            "INFO:tensorflow:loss = 0.099458106, step = 20101 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.155\n",
            "INFO:tensorflow:loss = 0.37084195, step = 20201 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.415\n",
            "INFO:tensorflow:loss = 0.19750696, step = 20301 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.024\n",
            "INFO:tensorflow:loss = 0.18403018, step = 20401 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.503\n",
            "INFO:tensorflow:loss = 0.019819265, step = 20501 (0.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.382\n",
            "INFO:tensorflow:loss = 0.25948682, step = 20601 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.797\n",
            "INFO:tensorflow:loss = 0.024735093, step = 20701 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.545\n",
            "INFO:tensorflow:loss = 0.10366684, step = 20801 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.839\n",
            "INFO:tensorflow:loss = 0.21828343, step = 20901 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 241.07\n",
            "INFO:tensorflow:loss = 0.06694602, step = 21001 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.79\n",
            "INFO:tensorflow:loss = 0.15337114, step = 21101 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.675\n",
            "INFO:tensorflow:loss = 0.18162034, step = 21201 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.275\n",
            "INFO:tensorflow:loss = 0.029296212, step = 21301 (0.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.578\n",
            "INFO:tensorflow:loss = 0.3053509, step = 21401 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 232.04\n",
            "INFO:tensorflow:loss = 0.20961004, step = 21501 (0.431 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.588\n",
            "INFO:tensorflow:loss = 0.1027818, step = 21601 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.982\n",
            "INFO:tensorflow:loss = 0.13464043, step = 21701 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.255\n",
            "INFO:tensorflow:loss = 0.075202204, step = 21801 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.228\n",
            "INFO:tensorflow:loss = 0.08873387, step = 21901 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.708\n",
            "INFO:tensorflow:loss = 0.066091135, step = 22001 (0.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.86\n",
            "INFO:tensorflow:loss = 0.09249957, step = 22101 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.356\n",
            "INFO:tensorflow:loss = 0.18757187, step = 22201 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.146\n",
            "INFO:tensorflow:loss = 0.074201584, step = 22301 (0.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.217\n",
            "INFO:tensorflow:loss = 0.12673163, step = 22401 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.483\n",
            "INFO:tensorflow:loss = 0.11639471, step = 22501 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.413\n",
            "INFO:tensorflow:loss = 0.071345255, step = 22601 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.556\n",
            "INFO:tensorflow:loss = 0.18824668, step = 22701 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.946\n",
            "INFO:tensorflow:loss = 0.062060345, step = 22801 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.688\n",
            "INFO:tensorflow:loss = 0.5710458, step = 22901 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.886\n",
            "INFO:tensorflow:loss = 0.07649256, step = 23001 (0.400 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.053\n",
            "INFO:tensorflow:loss = 0.10637676, step = 23101 (0.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.095\n",
            "INFO:tensorflow:loss = 0.09281057, step = 23201 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.487\n",
            "INFO:tensorflow:loss = 0.17898151, step = 23301 (0.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.085\n",
            "INFO:tensorflow:loss = 0.12308302, step = 23401 (0.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.645\n",
            "INFO:tensorflow:loss = 0.20231667, step = 23501 (0.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.186\n",
            "INFO:tensorflow:loss = 0.094899654, step = 23601 (0.398 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.342\n",
            "INFO:tensorflow:loss = 0.17394051, step = 23701 (0.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.576\n",
            "INFO:tensorflow:loss = 0.20249464, step = 23801 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.51\n",
            "INFO:tensorflow:loss = 0.22230878, step = 23901 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.311\n",
            "INFO:tensorflow:loss = 0.03892773, step = 24001 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.544\n",
            "INFO:tensorflow:loss = 0.18204519, step = 24101 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.628\n",
            "INFO:tensorflow:loss = 0.13108787, step = 24201 (0.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.625\n",
            "INFO:tensorflow:loss = 0.080766775, step = 24301 (0.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.328\n",
            "INFO:tensorflow:loss = 0.10450099, step = 24401 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.124\n",
            "INFO:tensorflow:loss = 0.17768832, step = 24501 (0.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.524\n",
            "INFO:tensorflow:loss = 0.24884768, step = 24601 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.013\n",
            "INFO:tensorflow:loss = 0.09656189, step = 24701 (0.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.653\n",
            "INFO:tensorflow:loss = 0.17457585, step = 24801 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.015\n",
            "INFO:tensorflow:loss = 0.11704061, step = 24901 (0.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.182\n",
            "INFO:tensorflow:loss = 0.03405054, step = 25001 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.9\n",
            "INFO:tensorflow:loss = 0.17642517, step = 25101 (0.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 239.641\n",
            "INFO:tensorflow:loss = 0.13246088, step = 25201 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.111\n",
            "INFO:tensorflow:loss = 0.03341157, step = 25301 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.063\n",
            "INFO:tensorflow:loss = 0.31217286, step = 25401 (0.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.941\n",
            "INFO:tensorflow:loss = 0.073501304, step = 25501 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.508\n",
            "INFO:tensorflow:loss = 0.22460762, step = 25601 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.891\n",
            "INFO:tensorflow:loss = 0.095611565, step = 25701 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.576\n",
            "INFO:tensorflow:loss = 0.011896824, step = 25801 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.385\n",
            "INFO:tensorflow:loss = 0.3016983, step = 25901 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.458\n",
            "INFO:tensorflow:loss = 0.119291045, step = 26001 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.081\n",
            "INFO:tensorflow:loss = 0.051789265, step = 26101 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 259.233\n",
            "INFO:tensorflow:loss = 0.17447984, step = 26201 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.49\n",
            "INFO:tensorflow:loss = 0.16317116, step = 26301 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.977\n",
            "INFO:tensorflow:loss = 0.12886557, step = 26401 (0.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.912\n",
            "INFO:tensorflow:loss = 0.109484434, step = 26501 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.975\n",
            "INFO:tensorflow:loss = 0.10373255, step = 26601 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.25\n",
            "INFO:tensorflow:loss = 0.15078813, step = 26701 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.457\n",
            "INFO:tensorflow:loss = 0.15715992, step = 26801 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.386\n",
            "INFO:tensorflow:loss = 0.16171648, step = 26901 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.401\n",
            "INFO:tensorflow:loss = 0.22916538, step = 27001 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.234\n",
            "INFO:tensorflow:loss = 0.032868113, step = 27101 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.476\n",
            "INFO:tensorflow:loss = 0.07313981, step = 27201 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.068\n",
            "INFO:tensorflow:loss = 0.13744237, step = 27301 (0.432 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.038\n",
            "INFO:tensorflow:loss = 0.08670998, step = 27401 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 284.922\n",
            "INFO:tensorflow:loss = 0.15760039, step = 27501 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.604\n",
            "INFO:tensorflow:loss = 0.04230671, step = 27601 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 281.648\n",
            "INFO:tensorflow:loss = 0.049112473, step = 27701 (0.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.795\n",
            "INFO:tensorflow:loss = 0.20070684, step = 27801 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.602\n",
            "INFO:tensorflow:loss = 0.3425296, step = 27901 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.346\n",
            "INFO:tensorflow:loss = 0.2882205, step = 28001 (0.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.816\n",
            "INFO:tensorflow:loss = 0.077180475, step = 28101 (0.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.928\n",
            "INFO:tensorflow:loss = 0.107826605, step = 28201 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.49\n",
            "INFO:tensorflow:loss = 0.042149294, step = 28301 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.69\n",
            "INFO:tensorflow:loss = 0.30539474, step = 28401 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.358\n",
            "INFO:tensorflow:loss = 0.11076536, step = 28501 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.708\n",
            "INFO:tensorflow:loss = 0.09312084, step = 28601 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.791\n",
            "INFO:tensorflow:loss = 0.19256467, step = 28701 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.98\n",
            "INFO:tensorflow:loss = 0.1496369, step = 28801 (0.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.109\n",
            "INFO:tensorflow:loss = 0.15506549, step = 28901 (0.409 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.668\n",
            "INFO:tensorflow:loss = 0.059153203, step = 29001 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.018\n",
            "INFO:tensorflow:loss = 0.07154462, step = 29101 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.142\n",
            "INFO:tensorflow:loss = 0.014426198, step = 29201 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.902\n",
            "INFO:tensorflow:loss = 0.039143547, step = 29301 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 276.633\n",
            "INFO:tensorflow:loss = 0.13700542, step = 29401 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.935\n",
            "INFO:tensorflow:loss = 0.1949025, step = 29501 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.097\n",
            "INFO:tensorflow:loss = 0.11965846, step = 29601 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.691\n",
            "INFO:tensorflow:loss = 0.15258245, step = 29701 (0.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.382\n",
            "INFO:tensorflow:loss = 0.069738574, step = 29801 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.705\n",
            "INFO:tensorflow:loss = 0.16024199, step = 29901 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.497\n",
            "INFO:tensorflow:loss = 0.1510759, step = 30001 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.584\n",
            "INFO:tensorflow:loss = 0.2968649, step = 30101 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.732\n",
            "INFO:tensorflow:loss = 0.06254941, step = 30201 (0.380 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.547\n",
            "INFO:tensorflow:loss = 0.07432179, step = 30301 (0.376 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.831\n",
            "INFO:tensorflow:loss = 0.08558731, step = 30401 (0.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.841\n",
            "INFO:tensorflow:loss = 0.09510727, step = 30501 (0.362 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.237\n",
            "INFO:tensorflow:loss = 0.113485746, step = 30601 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.437\n",
            "INFO:tensorflow:loss = 0.23518468, step = 30701 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.924\n",
            "INFO:tensorflow:loss = 0.049355313, step = 30801 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 278.834\n",
            "INFO:tensorflow:loss = 0.12038148, step = 30901 (0.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.302\n",
            "INFO:tensorflow:loss = 0.03395122, step = 31001 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.062\n",
            "INFO:tensorflow:loss = 0.033445254, step = 31101 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.428\n",
            "INFO:tensorflow:loss = 0.068007566, step = 31201 (0.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.862\n",
            "INFO:tensorflow:loss = 0.058896717, step = 31301 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.081\n",
            "INFO:tensorflow:loss = 0.064671464, step = 31401 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.773\n",
            "INFO:tensorflow:loss = 0.02385639, step = 31501 (0.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.037\n",
            "INFO:tensorflow:loss = 0.057683297, step = 31601 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.629\n",
            "INFO:tensorflow:loss = 0.03356528, step = 31701 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.436\n",
            "INFO:tensorflow:loss = 0.05212491, step = 31801 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.783\n",
            "INFO:tensorflow:loss = 0.0075060604, step = 31901 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.519\n",
            "INFO:tensorflow:loss = 0.07408064, step = 32001 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.049\n",
            "INFO:tensorflow:loss = 0.22082497, step = 32101 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.431\n",
            "INFO:tensorflow:loss = 0.13280211, step = 32201 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.675\n",
            "INFO:tensorflow:loss = 0.24050884, step = 32301 (0.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.275\n",
            "INFO:tensorflow:loss = 0.15942317, step = 32401 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.348\n",
            "INFO:tensorflow:loss = 0.28592074, step = 32501 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.2\n",
            "INFO:tensorflow:loss = 0.20005436, step = 32601 (0.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.138\n",
            "INFO:tensorflow:loss = 0.084634654, step = 32701 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.314\n",
            "INFO:tensorflow:loss = 0.030501084, step = 32801 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.291\n",
            "INFO:tensorflow:loss = 0.146129, step = 32901 (0.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 231.259\n",
            "INFO:tensorflow:loss = 0.1422869, step = 33001 (0.436 sec)\n",
            "INFO:tensorflow:global_step/sec: 234.744\n",
            "INFO:tensorflow:loss = 0.39218646, step = 33101 (0.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.748\n",
            "INFO:tensorflow:loss = 0.11588331, step = 33201 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.36\n",
            "INFO:tensorflow:loss = 0.19806182, step = 33301 (0.403 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.211\n",
            "INFO:tensorflow:loss = 0.22499986, step = 33401 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 254.837\n",
            "INFO:tensorflow:loss = 0.05972721, step = 33501 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.674\n",
            "INFO:tensorflow:loss = 0.09497032, step = 33601 (0.416 sec)\n",
            "INFO:tensorflow:global_step/sec: 246.827\n",
            "INFO:tensorflow:loss = 0.0653234, step = 33701 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.689\n",
            "INFO:tensorflow:loss = 0.050045304, step = 33801 (0.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 212.595\n",
            "INFO:tensorflow:loss = 0.050139014, step = 33901 (0.470 sec)\n",
            "INFO:tensorflow:global_step/sec: 226.89\n",
            "INFO:tensorflow:loss = 0.10249435, step = 34001 (0.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.245\n",
            "INFO:tensorflow:loss = 0.05378909, step = 34101 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 222.732\n",
            "INFO:tensorflow:loss = 0.06776846, step = 34201 (0.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.302\n",
            "INFO:tensorflow:loss = 0.06728485, step = 34301 (0.465 sec)\n",
            "INFO:tensorflow:global_step/sec: 218.932\n",
            "INFO:tensorflow:loss = 0.5195844, step = 34401 (0.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 233.362\n",
            "INFO:tensorflow:loss = 0.22798552, step = 34501 (0.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 227.564\n",
            "INFO:tensorflow:loss = 0.24768923, step = 34601 (0.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 235.51\n",
            "INFO:tensorflow:loss = 0.10576282, step = 34701 (0.422 sec)\n",
            "INFO:tensorflow:global_step/sec: 228.209\n",
            "INFO:tensorflow:loss = 0.18095928, step = 34801 (0.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.968\n",
            "INFO:tensorflow:loss = 0.10177248, step = 34901 (0.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.439\n",
            "INFO:tensorflow:loss = 0.18112032, step = 35001 (0.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 219.257\n",
            "INFO:tensorflow:loss = 0.012134598, step = 35101 (0.456 sec)\n",
            "INFO:tensorflow:global_step/sec: 240.708\n",
            "INFO:tensorflow:loss = 0.0564931, step = 35201 (0.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.709\n",
            "INFO:tensorflow:loss = 0.11002234, step = 35301 (0.391 sec)\n",
            "INFO:tensorflow:global_step/sec: 262.236\n",
            "INFO:tensorflow:loss = 0.09405847, step = 35401 (0.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.222\n",
            "INFO:tensorflow:loss = 0.18131481, step = 35501 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 265.447\n",
            "INFO:tensorflow:loss = 0.03237117, step = 35601 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.106\n",
            "INFO:tensorflow:loss = 0.018061955, step = 35701 (0.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.496\n",
            "INFO:tensorflow:loss = 0.109802105, step = 35801 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.31\n",
            "INFO:tensorflow:loss = 0.060915284, step = 35901 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.44\n",
            "INFO:tensorflow:loss = 0.10540437, step = 36001 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.393\n",
            "INFO:tensorflow:loss = 0.107544936, step = 36101 (0.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.517\n",
            "INFO:tensorflow:loss = 0.06318386, step = 36201 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 253.718\n",
            "INFO:tensorflow:loss = 0.12745132, step = 36301 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.42\n",
            "INFO:tensorflow:loss = 0.033561505, step = 36401 (0.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.308\n",
            "INFO:tensorflow:loss = 0.16822885, step = 36501 (0.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.026\n",
            "INFO:tensorflow:loss = 0.18357247, step = 36601 (0.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.852\n",
            "INFO:tensorflow:loss = 0.04870282, step = 36701 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.274\n",
            "INFO:tensorflow:loss = 0.03212352, step = 36801 (0.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.285\n",
            "INFO:tensorflow:loss = 0.20606756, step = 36901 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.364\n",
            "INFO:tensorflow:loss = 0.077874206, step = 37001 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 258.027\n",
            "INFO:tensorflow:loss = 0.14772302, step = 37101 (0.392 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.296\n",
            "INFO:tensorflow:loss = 0.017277004, step = 37201 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.201\n",
            "INFO:tensorflow:loss = 0.13081814, step = 37301 (0.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.94\n",
            "INFO:tensorflow:loss = 0.13418652, step = 37401 (0.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.486\n",
            "INFO:tensorflow:loss = 0.1921888, step = 37501 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.541\n",
            "INFO:tensorflow:loss = 0.086370505, step = 37601 (0.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.778\n",
            "INFO:tensorflow:loss = 0.15261394, step = 37701 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 274.631\n",
            "INFO:tensorflow:loss = 0.13789737, step = 37801 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 272.592\n",
            "INFO:tensorflow:loss = 0.2906586, step = 37901 (0.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.443\n",
            "INFO:tensorflow:loss = 0.12841901, step = 38001 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.365\n",
            "INFO:tensorflow:loss = 0.07105323, step = 38101 (0.371 sec)\n",
            "INFO:tensorflow:global_step/sec: 270.124\n",
            "INFO:tensorflow:loss = 0.034384478, step = 38201 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.575\n",
            "INFO:tensorflow:loss = 0.40652055, step = 38301 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.669\n",
            "INFO:tensorflow:loss = 0.2348839, step = 38401 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.582\n",
            "INFO:tensorflow:loss = 0.10474025, step = 38501 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 263.7\n",
            "INFO:tensorflow:loss = 0.031073952, step = 38601 (0.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 275.002\n",
            "INFO:tensorflow:loss = 0.044886928, step = 38701 (0.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 289.06\n",
            "INFO:tensorflow:loss = 0.4335205, step = 38801 (0.349 sec)\n",
            "INFO:tensorflow:global_step/sec: 273.353\n",
            "INFO:tensorflow:loss = 0.084259726, step = 38901 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 280.758\n",
            "INFO:tensorflow:loss = 0.20193611, step = 39001 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 267.836\n",
            "INFO:tensorflow:loss = 0.014738517, step = 39101 (0.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 266.155\n",
            "INFO:tensorflow:loss = 0.13121153, step = 39201 (0.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.426\n",
            "INFO:tensorflow:loss = 0.16522175, step = 39301 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 260.588\n",
            "INFO:tensorflow:loss = 0.11872294, step = 39401 (0.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.409\n",
            "INFO:tensorflow:loss = 0.047215614, step = 39501 (0.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 271.838\n",
            "INFO:tensorflow:loss = 0.11561224, step = 39601 (0.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.095\n",
            "INFO:tensorflow:loss = 0.02517513, step = 39701 (0.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 268.319\n",
            "INFO:tensorflow:loss = 0.037915558, step = 39801 (0.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 269.893\n",
            "INFO:tensorflow:loss = 0.07375505, step = 39901 (0.376 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/tmp1ao_uxgb/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.19718845.\n",
            "\n",
            "Training Time = 0:02:41.828993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aV5GHPpzZMy",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4-teoD1L_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "910bc299-e875-4d60-f806-4f6c61f9c84d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "y_pred = list(dnn_clf.predict(x_test))\n",
        "dnnScore = accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:574: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
            "Instructions for updating:\n",
            "Please switch to predict_classes, or set `outputs` argument.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:463: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1ao_uxgb/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgb2UNUv1aki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e9c7405d-ee15-41bf-e61f-a366c0bd98fa"
      },
      "source": [
        "print(\"DNN Accuracy Rating:\", dnnScore*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DNN Accuracy Rating: 94.69 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBq_2mwLT95Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "6d107bc5-dddc-43f8-eb84-8fcf8e13f04a"
      },
      "source": [
        "resultsDNN = dnn_clf.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-13T03:50:49Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp1ao_uxgb/model.ckpt-40000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-13-03:50:50\n",
            "INFO:tensorflow:Saving dict for global step 40000: accuracy = 0.9469, global_step = 40000, loss = 0.26439846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA2Cww1NUIks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9d5f9eda-4d6d-4b24-c692-92e3badfe09c"
      },
      "source": [
        "print(resultsDNN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': 0.26439846, 'accuracy': 0.9469, 'global_step': 40000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xJo4axRqlX6",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nud7CNjTen4A",
        "colab_type": "text"
      },
      "source": [
        "### Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys25VqOPVMaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "0328d8e2-e000-4c10-b7e8-2400ae99854e"
      },
      "source": [
        "\n",
        "test_error, confusions = error_rate(test_prediction.eval(), test_labels)\n",
        "print('Test error: %.1f%%' % test_error)\n",
        "\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.grid(False)\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.yticks(numpy.arange(NUM_LABELS))\n",
        "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
        "\n",
        "for i, cas in enumerate(confusions):\n",
        "    for j, count in enumerate(cas):\n",
        "        if count > 0:\n",
        "            xoff = .07 * len(str(count))\n",
        "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')\n",
        "\n",
        "\n",
        "# We can see here that we're mostly accurate, with some errors you might expect, e.g., '9' is often confused as '4'.\n",
        "# \n",
        "# Let's do another sanity check to make sure this matches roughly the distribution of our test set, e.g., it seems like we have fewer '5' values.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test error: 1.9%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAEGCAYAAACO3ptGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9XqEG6dVOrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "b649a47b-b99f-4477-90a4-289f30dab7f0"
      },
      "source": [
        "\n",
        "plt.xticks(numpy.arange(NUM_LABELS))\n",
        "plt.hist(numpy.argmax(test_labels, 1));\n",
        "\n",
        "\n",
        "# Indeed, we appear to have fewer 5 labels in the test set. So, on the whole, it seems like our model is learning and our early results are sensible.\n",
        "# \n",
        "# But, we've only done one round of training. We can greatly improve accuracy by training for longer. To try this out, just re-execute the training cell above.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFKCAYAAADScRzUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAA/XHaAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sMOaT_OgwcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "14e99b30-890d-4085-b5a6-e1f5c7ec56a7"
      },
      "source": [
        "results_df = pd.DataFrame({'TestName': ['TensorFlow DNN', 'Basic NN', 'Keras CNN'],\n",
        "   'Test Accuracy': [0.9808, 0.9469, 0.9921],\n",
        "   'Training Time': ['0:02:56', '0:02:48', '1:23:30']})\n",
        "results_df.set_index('TestName', inplace=True)\n",
        "\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TestName</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TensorFlow DNN</th>\n",
              "      <td>0.9808</td>\n",
              "      <td>0:02:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Basic NN</th>\n",
              "      <td>0.9469</td>\n",
              "      <td>0:02:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Keras CNN</th>\n",
              "      <td>0.9921</td>\n",
              "      <td>1:23:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Test Accuracy Training Time\n",
              "TestName                                   \n",
              "TensorFlow DNN         0.9808       0:02:56\n",
              "Basic NN               0.9469       0:02:48\n",
              "Keras CNN              0.9921       1:23:30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7r0pBAEkXnR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "I trained 3 different neural networks. The Keras CNN model performed the best but the training time was almost an hour and a half. This was very long in comparison to the other models. The basic NN model trained the quickest but the results were inconsistent.\n",
        "\n",
        "<br>\n",
        "\n",
        "**I would recommend using the TensorFlow NN because it will save time/money during training but it maintains high accuracy predicting new data.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et1L3vy8LrBF",
        "colab_type": "text"
      },
      "source": [
        "# Cats and Dogs Jumpstart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI5SnUdNLv9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Common imports for our work\n",
        "import os \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEE7IUfbLxzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 9999"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyHDZMF4Lzus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To make output stable across runs\n",
        "def reset_graph(seed= RANDOM_SEED):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIK2K8FhL1QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CatsDogs# Old dimensions from MNIST no loger apply\n",
        "#CatsDogs# height = 28\n",
        "#CatsDogs# width = 28\n",
        "height = 64\n",
        "width = 64   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPa1YMPVMc4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6c134597-8060-4f82-c25b-0baf40c87a7e"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjqY-p0NMdA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46016d41-741f-41ff-ba14-7d6d3f8aeacb"
      },
      "source": [
        "# set working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/422 - Practical Machine Learning/Colab Notebooks/Assignment 7/\")\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/422 - Practical Machine Learning/Colab Notebooks/Assignment 7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJVALpKBMdGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "005783f0-c09e-47f1-ac8b-1ad824a7d9bf"
      },
      "source": [
        "# list files in data folder\n",
        "!ls \"cats_dogs_64-128/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats_1000_64_64_1.npy  dogs_1000_64_64_1.npy\n",
            "cats_1000_64_64_3.npy  dogs_1000_64_64_3.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km1i-YDuM_Ya",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSzbwPBLL2jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CatsDogs# \n",
        "# Documentation on npy binary format for saving numpy arrays for later use\n",
        "#     https://towardsdatascience.com/\n",
        "#             why-you-should-start-using-npy-file-more-often-df2a13cc0161\n",
        "# Under the working directory, data files are in directory cats_dogs_64_128 \n",
        "# Read in cats and dogs grayscale 64x64 files to create training data\n",
        "cats_1000_64_64_1 = np.load('cats_dogs_64-128/cats_1000_64_64_1.npy')\n",
        "dogs_1000_64_64_1 = np.load('cats_dogs_64-128/dogs_1000_64_64_1.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L43mgLsTM87y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt  # for display of images\n",
        "\n",
        "def show_grayscale_image(image):\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJBcMJ79NrON",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wxHfvM1NE8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "e497254f-8393-4222-9dfc-e371e486542f"
      },
      "source": [
        "# Examine first cat and first dog grayscale images\n",
        "show_grayscale_image(cats_1000_64_64_1[0,:,:,0])\n",
        "show_grayscale_image(dogs_1000_64_64_1[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCP4L7SgZZKujXy0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "521B797gNsti",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-SKqV6jNT5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 300 and 100 nodes for layers 1 and 2 as used with MNIST from Geron\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "\n",
        "channels = 1  # When working with color images use channels = 3\n",
        "\n",
        "n_inputs = height * width\n",
        "\n",
        "#CatsDogs# Has two output values # MNIST had ten digits n_outputs = 10  \n",
        "n_outputs = 2  # binary classification for Cats and Dogs, 1 output node 0/1\n",
        "\n",
        "reset_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH_nknXINi7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a5848793-e8ca-449d-e430-cfb0f404c934"
      },
      "source": [
        "# load datasets\n",
        "start=datetime.now()\n",
        "\n",
        "# dnn... Deep neural network model from Geron Chapter 10\n",
        "# Note that this model makes no use of the fact that we have\n",
        "# pixel data arranged in rows and columns\n",
        "# So a 64x64 matrix of raster values becomes a vector of 4096 input variables\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "def neuron_layer(X, n_neurons, name, activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        stddev = 2 / np.sqrt(n_inputs)\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
        "        W = tf.Variable(init, name=\"kernel\")\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
        "        Z = tf.matmul(X, W) + b\n",
        "        if activation is not None:\n",
        "            return activation(Z)\n",
        "        else:\n",
        "            return Z\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
        "                           activation=tf.nn.relu)\n",
        "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                           activation=tf.nn.relu)\n",
        "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                              logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "    \n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    \n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "0:00:00.289358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0FEC6o_OAJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Work the data for cats and dogs numpy arrays \n",
        "# These numpy arrays were generated in previous data prep work\n",
        "# Stack the numpy arrays for the inputs\n",
        "X_cat_dog = np.concatenate((cats_1000_64_64_1, dogs_1000_64_64_1), axis = 0) \n",
        "X_cat_dog = X_cat_dog.reshape(-1,width*height) # note coversion to 4096 inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzIhfQm4PWTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the labels to be used 1000 cats = 0 1000 dogs = 1\n",
        "y_cat_dog = np.concatenate((np.zeros((1000), dtype = np.int32), \n",
        "                      np.ones((1000), dtype = np.int32)), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85P6Zo4P9sH",
        "colab_type": "text"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO-vGxbyOQR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X_cat_dog, y_cat_dog, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmNaPtUYP_QH",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtYomq31PzEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "d6668940-373b-438a-b16b-fd8636adfb5d"
      },
      "source": [
        "\n",
        "init = tf.global_variables_initializer()    \n",
        "\n",
        "n_epochs = 50\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(y_train.shape[0] // batch_size):\n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "\n",
        "        save_path = saver.save(sess, \"./my_catdog_model\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.59 Test accuracy: 0.4875\n",
            "1 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "2 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "3 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "4 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "5 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "6 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "7 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "8 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "9 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "10 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "11 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "12 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "13 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "14 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "15 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "16 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "17 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "18 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "19 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "20 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "21 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "22 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "23 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "24 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "25 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "26 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "27 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "28 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "29 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "30 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "31 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "32 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "33 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "34 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "35 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "36 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "37 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "38 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "39 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "40 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "41 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "42 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "43 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "44 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "45 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "46 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "47 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "48 Train accuracy: 0.59 Test accuracy: 0.4825\n",
            "49 Train accuracy: 0.59 Test accuracy: 0.4825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGd8HEdJQEiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0cIF_TQ82O",
        "colab_type": "text"
      },
      "source": [
        "## Keras CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRLEkChEgPtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8ip882eLAs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18kDdAjLAwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7R7g3mLAqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSctHM2ILAn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3AmHBQLAll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "ed6b82c1-fe5b-41a0-a66d-b0da8c762fe9"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzxC8E5iLAig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dE7_n_fLAfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-T7IJ-ZLAcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z58r7Wnpgnf4",
        "colab_type": "text"
      },
      "source": [
        "### Adding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXn_Q1zALAZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ca570137-dcc5-478b-d0cb-db748ecd75c4"
      },
      "source": [
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation=Activation(tf.nn.softmax)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as Activation) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdcFFcbCgv8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdObdiQSzjN0",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NgtSjWngwGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "27434ec5-e436-4e4a-f35e-2ee8ea6868b1"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 510s 8ms/step - loss: 0.2417 - acc: 0.9258 - val_loss: 0.0494 - val_acc: 0.9837\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 501s 8ms/step - loss: 0.0765 - acc: 0.9777 - val_loss: 0.0357 - val_acc: 0.9890\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 496s 8ms/step - loss: 0.0550 - acc: 0.9845 - val_loss: 0.0372 - val_acc: 0.9883\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 497s 8ms/step - loss: 0.0470 - acc: 0.9858 - val_loss: 0.0330 - val_acc: 0.9891\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 498s 8ms/step - loss: 0.0379 - acc: 0.9884 - val_loss: 0.0234 - val_acc: 0.9923\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 496s 8ms/step - loss: 0.0326 - acc: 0.9900 - val_loss: 0.0277 - val_acc: 0.9909\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 499s 8ms/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0238 - val_acc: 0.9920\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 499s 8ms/step - loss: 0.0251 - acc: 0.9920 - val_loss: 0.0229 - val_acc: 0.9915\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 500s 8ms/step - loss: 0.0233 - acc: 0.9930 - val_loss: 0.0270 - val_acc: 0.9914\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 502s 8ms/step - loss: 0.0226 - acc: 0.9932 - val_loss: 0.0220 - val_acc: 0.9921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0f82a94a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ek3O41gU83j",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmLtN-TzgwQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d6e555c1-c1c8-4269-fe0e-9796b8302f04"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.022031682752041887\n",
            "Test accuracy: 0.9921\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}